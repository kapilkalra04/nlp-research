{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kapilkalra04\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kapilkalra04\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [\n",
    "    'Industrial Disease',\n",
    "'Private Investigations',\n",
    "'So Far Away',\n",
    "'Twisting by the Pool',\n",
    "'Skateaway',\n",
    "'Walk of Life',\n",
    "'Romeo and Juliet',\n",
    "'Tunnel of Love',\n",
    "'Money for Nothing',\n",
    "'Sultans of Swing',\n",
    "'Stairway To Heaven',\n",
    "'Kashmir',\n",
    "'Achilles Last Stand',\n",
    "'Whole Lotta Love',\n",
    "'Immigrant Song',\n",
    "'Black Dog',\n",
    "'When The Levee Breaks',\n",
    "'Since I\\'ve Been Lovin\\' You',\n",
    "'Since I\\'ve Been Loving You',\n",
    "'Over the Hills and Far Away',\n",
    "'Dazed and Confused' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "     return nltk.tokenize.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Lotta Love\n",
      "['Whole', 'Lotta', 'Love']\n"
     ]
    }
   ],
   "source": [
    "print input[13]\n",
    "print tokenize(input[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LEMMATIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(word):\n",
    "    return wnl.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Lotta Love\n",
      "['Whole', 'Lotta', 'Love']\n",
      "Whole\n",
      "Lotta\n",
      "Love\n"
     ]
    }
   ],
   "source": [
    "print input[13]\n",
    "print tokenize(input[13])\n",
    "for w in tokenize(input[13]):\n",
    "    print lemmatize(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
